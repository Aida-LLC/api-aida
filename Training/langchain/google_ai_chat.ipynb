{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/langchain-google-genai/\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAIes7F5Af0XvA5IVV3umNKMpCXzvpMLdY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "result = llm.invoke(\"Write a ballad about LangChain\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"style\"],\n",
    "    template=\"Please answer the following question: {question} in the style of {style}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genAi = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, fam! We feel anger and love cuz they're like, totally human emotions, ya feel? Anger is like, when you're all fired up and ready to throw a fit, right? It's like, when your bestie cancels on you last minute, you're gonna be mad AF. But love is like, when your heart's all mushy and you wanna cuddle with your boo. It's like, when you see your crush and your tummy does a lil' flip. So, yeah, anger and love are just part of the human experience, and it's all good, bae.\n"
     ]
    }
   ],
   "source": [
    "response = genAi.run(question=\"Why do we feel anger and love?\", style=\"GenZ teen\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, fam! We feel anger and love cuz they're like, totally human emotions, ya\n",
      "feel? Anger is like, when you're all fired up and ready to throw a fit, right?\n",
      "It's like, when your bestie cancels on you last minute, you're gonna be mad AF.\n",
      "But love is like, when your heart's all mushy and you wanna cuddle with your\n",
      "boo. It's like, when you see your crush and your tummy does a lil' flip. So,\n",
      "yeah, anger and love are just part of the human experience, and it's all good,\n",
      "bae.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def wrap_text(text, width=80):\n",
    "    return textwrap.fill(text, width)\n",
    "\n",
    "print(wrap_text(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf\n",
    "# !pip install langchain_community --upgrade\n",
    "# !pip install faiss-cpu --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/software_inspection.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = FAISS.from_documents(pages, GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 9:\n",
      "6.6.2 Inspectors and Roles\n",
      "There are four inspector roles identiﬁed in a Fagan Inspection and they are\n",
      "described in Table 6.7.\n",
      "6.6.3 Inspection Entry Criteria\n",
      "There are explicit entry and exit criteria deﬁned for the various types of inspections.\n",
      "These criteria need to be satisﬁed to ensure that the inspection is effective. The\n",
      "entry criteria for the various inspections are given in Table 6.8.\n",
      "6.6.4 Preparation\n",
      "Preparation is a key part of the inspection process, as the inspection will be\n",
      "ineffe\n",
      "\n",
      "\n",
      "\n",
      "Page 7:\n",
      "6.6 Fagan Inspections\n",
      "The Fagan methodology (Table 6.4) is a well-known software inspection\n",
      "methodology. It is a seven-step process and includes planning, overview, prepara-\n",
      "tion, inspection meeting, process improvement, re-work, and follow-up activity.\n",
      "Its objectives are to identify and remove errors in the work products, and also to\n",
      "identify any systemic defects in the processes used to create the work products.\n",
      "The Fagan inspection process stipulates that requirement documents, design\n",
      "documen\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is fagan inspection?\"\n",
    "\n",
    "\n",
    "docs = faiss_index.similarity_search(query, k=2)\n",
    "for doc in docs:\n",
    "    doc_page = doc.metadata[\"page\"]\n",
    "    print(f\"Page {doc_page}:\")\n",
    "\n",
    "    print(doc.page_content[:500])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 9: 0.5453141927719116 \n",
      " 6.6.2 Inspectors and Roles\n",
      "There are four inspector roles identiﬁed in a Fagan Inspection and they a \n",
      "\n",
      "\n",
      "Page 7: 0.5675018429756165 \n",
      " 6.6 Fagan Inspections\n",
      "The Fagan methodology (Table 6.4) is a well-known software inspection\n",
      "methodol \n",
      "\n",
      "\n",
      "Page 17: 0.5806626081466675 \n",
      " informal and usually takes place at the author’s desk or in a meeting room, and the\n",
      "reviewer and aut \n",
      "\n",
      "\n",
      "Page 0: 0.5858128070831299 \n",
      " Software Inspections6\n",
      "Key Topics\n",
      "Fagan Inspection\n",
      "Gilb Inspections\n",
      "Economic Beneﬁts of Inspection\n",
      "In \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_with_scores = faiss_index.similarity_search_with_score(query)\n",
    "\n",
    "for item in search_with_scores:\n",
    "    print(f\"Page {item[0].metadata['page']}: {item[1]} \\n {item[0].page_content[:100]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
